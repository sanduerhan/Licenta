{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Column2   Column3\n",
      "0     Waiting for my mind to have a breakdown once t...  moderate\n",
      "1     My new years resolution : I'm gonna get my ass...  moderate\n",
      "2     New year : Somone else Feeling like 2020 will ...  moderate\n",
      "3     My story I guess : Hi, Im from Germany and my ...  moderate\n",
      "4     Sat in the dark and cried myself going into th...  moderate\n",
      "...                                                 ...       ...\n",
      "8886  Ways to reverse memory loss from depression? :...    severe\n",
      "8887  A Comprehensive Guide To Slowly Getting Better...    severe\n",
      "8888  I don’t think college is right for me : TW: su...    severe\n",
      "8889  Please help: Severe insomnia affecting me in m...    severe\n",
      "8890  With each passing day my depression is getting...    severe\n",
      "\n",
      "[8891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#importing the dataset\n",
    "import pandas as pd\n",
    "col_list = [\"Column2\", \"Column3\"]\n",
    "col_list2 = [\"Column2\"]\n",
    "dataset = pd.read_excel(\"Training.data.xlsx\", usecols=col_list)\n",
    "testnset = pd.read_excel(\"Test.data.xlsx\", usecols=col_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting mind breakdown new year feeling isnt anymore dont know anyone else im little bit worried ill go back depressed days time something last year tried breakdowns start mere days later broke crying wasnt entire year december ok month wait weird way act feel feels bit normal\n"
     ]
    }
   ],
   "source": [
    "# cleaning the text : deleting the emojis, the existing emails, the punctuation, the present digits,\n",
    "# the hyperlinks and the stopwords (a,the,is, etc)\n",
    "import nltk\n",
    "import openpyxl\n",
    "from nltk.corpus import stopwords, words, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re, string\n",
    "from string import punctuation, digits\n",
    "def delete_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)  # no emoji\n",
    "\n",
    "\n",
    "def delete_digits(text):\n",
    "    text = text.lower()\n",
    "    clean = text.translate(str.maketrans('', '', digits))\n",
    "    return clean\n",
    "\n",
    "\n",
    "def delete_punctuation(text):\n",
    "    clean = text.translate(str.maketrans('', '', punctuation + '’“”'))\n",
    "    return clean\n",
    "\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "punct = list(string.punctuation)\n",
    "stop.update(punct)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "\n",
    "def remove_hyperlinks(text):\n",
    "    for word in text:\n",
    "        if re.match(r'^http', word):\n",
    "            text.remove(word)\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def remove_emails(text):\n",
    "    text = text.split()\n",
    "    for i in text:\n",
    "        if '@' in i.strip().lower():\n",
    "            text.remove(i)\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = remove_emails(text)\n",
    "    text = delete_punctuation(text)\n",
    "    text = delete_emoji(text)\n",
    "    text = delete_digits(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = text.split()\n",
    "    text = remove_hyperlinks(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "dataset['Column2'] = dataset['Column2'].apply(denoise_text)\n",
    "print(dataset['Column2'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait mind breakdown new year feel isnt anymore dont know anyone else im little bit worried ill go back depressed day time something last year try breakdown start mere day later broke cry wasnt entire year december ok month wait weird way act feel feel bit normal\n"
     ]
    }
   ],
   "source": [
    "# lemmatization : crying -> cry, days -> day\n",
    "def get_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemm(text):\n",
    "    text = text.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sar_list_lemmatizer = [lemmatizer.lemmatize(word, get_pos(word)) for word in text]\n",
    "    return \" \".join(sar_list_lemmatizer)\n",
    "\n",
    "print(lemm(dataset['Column2'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12552)\t1\n",
      "  (0, 7222)\t1\n",
      "  (0, 1397)\t1\n",
      "  (0, 7593)\t1\n",
      "  (0, 12994)\t3\n",
      "  (0, 4256)\t1\n",
      "  (0, 6149)\t1\n",
      "  (0, 541)\t1\n",
      "  (0, 3353)\t1\n",
      "  (0, 6384)\t1\n",
      "  (0, 545)\t1\n",
      "  (0, 3663)\t1\n",
      "  (0, 5726)\t1\n",
      "  (0, 6671)\t1\n",
      "  (0, 1177)\t2\n",
      "  (0, 12906)\t1\n",
      "  (0, 5715)\t1\n",
      "  (0, 4929)\t1\n",
      "  (0, 872)\t1\n",
      "  (0, 2936)\t1\n",
      "  (0, 2744)\t2\n",
      "  (0, 11694)\t1\n",
      "  (0, 10616)\t1\n",
      "  (0, 6447)\t1\n",
      "  (0, 11922)\t1\n",
      "  :\t:\n",
      "  (8890, 4993)\t2\n",
      "  (8890, 11516)\t2\n",
      "  (8890, 5020)\t1\n",
      "  (8890, 5000)\t1\n",
      "  (8890, 1337)\t1\n",
      "  (8890, 537)\t1\n",
      "  (8890, 273)\t1\n",
      "  (8890, 5228)\t1\n",
      "  (8890, 10625)\t1\n",
      "  (8890, 7651)\t1\n",
      "  (8890, 222)\t1\n",
      "  (8890, 11532)\t1\n",
      "  (8890, 7)\t1\n",
      "  (8890, 5281)\t2\n",
      "  (8890, 5375)\t1\n",
      "  (8890, 3476)\t1\n",
      "  (8890, 9090)\t1\n",
      "  (8890, 10139)\t1\n",
      "  (8890, 5209)\t1\n",
      "  (8890, 2025)\t1\n",
      "  (8890, 6319)\t2\n",
      "  (8890, 6481)\t1\n",
      "  (8890, 2184)\t1\n",
      "  (8890, 10162)\t1\n",
      "  (8890, 1808)\t1\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer reprezentation for the user tweets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "x_train = dataset['Column2']\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train)\n",
    "x_train_dtm = vectorizer.transform(x_train)\n",
    "\n",
    "x_train_dtm = vectorizer.fit_transform(x_train)\n",
    "# print(x_train_dtm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}